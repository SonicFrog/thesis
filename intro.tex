\chapter{Introduction}

Applications such as websearch, e-commerce, and social networking have
strict tail-latency service level objectives (SLOs) to maintain users'
attention~\cite{url:attention}.
While modern networking infrastructure allows for network transfers at
40 and 100Gbps, and round-trip latencies in a handful of
microseconds~\cite{nicperf}, existing operating systems and application
software can prevent applications from achieving close to hardware
performance~\cite{ix}.
Thus, both academia and industry have focused on reducing the
overheads coming from deep software stacks and inefficient system
implementation, so that applications can perform as close to the hardware
limits as possible.

Dataplane operating systems are such an approach that aims to optimize
throughput and latency for certain types of applications, such as
key-value stores.
Dataplane operating trade-off generality for performance, since they
can afford to simplify their networking stack, given that they serve
one specific application.
Systems such as IX~\cite{ix} and Arrakis~\cite{arrakis} showed that
re-using design principles well-known from middleboxes, can
significantly improve the application performance,
both in terms of throughput, tail-latency and latency stability.

However, the above systems try to maintain compatibility with
existing applications and only allowed minimal changes to the POSIX
API.
Moreover, the boundaries between the application and networking stack are distinct
and the networking stack and operating system are agnostic to the application running on top of them.
This design decision, though, prevented aggressive optimisations
that would be possible in the case of co-designing the application
with the networking stack.
For example, the way TCP is exposed to applications through POSIX
sockets, inherently implies copies between the application and the
OS.
These redundant copies can affect the tail-latency, especially in the presence of large values,
and could potentially be eliminated with careful engineering of the application and the networking stack.

In this thesis, we attempt to co-design and implement a key-value
store with the networking stack that depends on a reliable transport,
while at the same time completely eliminating copies both on the
receive and transmit path.
To do so, we leverage Rust~\cite{rustbook}, a new systems programming
language, that
guarantees memory safety through an explicit memory onwernship model.
By using Rust we can reason at compile time about the memory ownership
that can change between the application and the networking stack.

We implemented a key-value store based on the Redis~\cite{url:redis}
API on top of Intel's DPDK~\cite{dpdk} and serves requests over R2P2,
a reliable transport protocol specifically designed for remote
procedure calls (RPCs). Our key-value store depends on a lock-free
store that eliminates data copies between the application and the
networking stack. The key-value pairs are stored inside the networked
buffers as they arrive to the server after a \texttt{set} operation,
and the access to these network buffers is managed by Rust's explicit
ownership model, thus preventing any race conditions.

The evaluation, while still incomplete, shows that Rust offers
acceptable performance and considering the advantages it offers when
dealing with highly concurrent software we think the performance
penalty is well worth it.

The rest of this document is organised as follows: % \marios{FIXME!}
\begin{itemize}
\item We will first explore a little background on the topic in
  chapter~\ref{chap:background}
\item We will then explain how we intend to design the system in
  chapter~\ref{chap:design}
\item After that we will see how the abstract design translates into a
  concrete Rust implementation in chapter~\ref{chap:implementation}
\item Finally we will evaluate how our system performs compared to
  other similar systems in chapter~\ref{chap:evaluation}.
\item And to conclude we will mention what further work could be done
  to improve on the current system in chapter~\ref{chap:work}
\end{itemize}
