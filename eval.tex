\label{chap:evaluation}

We will now evaluate the performance of the system as well as the
performance of the local store.

The server benchmarks are run on an Intel Xeon E5-2637 @ 3.50 Ghz
machine with 64 GB of RAM, running Ubuntu. The machines have Intel
82599ES 10-Gigabit NICs. Since we make heavy use of experimental Rust
APIs, we use the Rust nightly 1.28. NetBricks also requires Rust
nightly and is built on top of DPDK 17.05.

\section{Local store}
\label{sec:eval-local}

We first evaluate how the local hashmap performance, especially when
under a lot of load. We use UTF-8 string keys of 128 bytes with values
of 64 bits to simulate only copying pointers to packets from the
network. We generate a random workload for each of the 15 concurrent
thread and start them simultaneously. To avoid scheduling overhead
each thread is bound to a physical through the Linux core affinity
API\@. Each workload is made of one million GET and 1 million PUT
request, on a previously initialized map.

\subsection{No collisions, balanced load}

We first establish the optimal performance we can expect from the
hashmap by reducing the contention on the buckets, thus reducing the
amount of wasted work by threads trying to swap out the buckets
unsuccessfully. To this end, we allocate four times more buckets than
they are keys and using a uniform distribution when generating
workload. The set of keys is pre-determined and no new keys are
inserted throughout the test, meaning the size of each bucket will
stay constant.

\begin{center}
  \begin{tabular}{c c} \label{table:nocol-balanced}
    \includegraphics[width=0.5\textwidth]{../csv/balanced_no_collision_PUT.pdf}
    &
      \includegraphics[width=0.5\textwidth]{../csv/balanced_no_collision_GET.pdf}
  \end{tabular}
  \captionof{figure}{Distribution of request durations}
\end{center}

The orange line is the median value of request durations. The median
value for GET request time is 520ns and it is 700ns for PUT request in
the case where we minimize collisions. Considering that there is a
non-compressible 4.5 microseconds time to perform PCI transactions
when sending packets the key-value store won't be the major latency
inducing part of the system in the case where collisions are low.

\subsection{Artificial collision, balanced load}

OMVCC scheme are known for performing badly under write heavy
workloads. So we now consider the case of a skewed and write heavy
workload and evaluate the performance of the hashmap in this
scenario. In order to simulate a skewed workload, we reduce the number
of buckets in the hashmap. This will create lots of contention between
threads for each buckets since the chance of two keys mapping to the
same bucket is increased by a factor of 4. The test setup is, again,
the same as described in section~\ref{sec:eval-local}.

\begin{center}
  \begin{tabular}{c c} \label{table:col-balanced}
    \includegraphics[width=0.5\textwidth]{../csv/balanced_collision_PUT.pdf}
    &
      \includegraphics[width=0.5\textwidth]{../csv/balanced_collision_GET.pdf}
  \end{tabular}
  \captionof{figure}{Distribution of request durations with collision}
\end{center}

The goal of this test setup is to evaluate how the key-value store
will perform in adverse conditions. As we can see the median has
increased by around 200ns on PUT requests, which is to be expected
since there will be more attempts where work will need to be done more
than once because of the contention on buckets.

We also notice a slight increase in GET times. This is most likely due
to the atomic instructions used to fetch buckets that can cause
stalling due to the necessity of synchronizing memory accesses across
cores. However even when introducing high collision rate the hashmap
still has reasonable performance.

\section{Networked store}

Though we hoped to have the performance evaluation of the system as a
whole ready, a few unforeseen problems surfaced at the last
minute. These problems (related to low-level DPDK implementation
details) prevented us from providing a comprehensive performance
evaluation of the whole system. Nonetheless we will try to have one
ready for the defense.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End:
